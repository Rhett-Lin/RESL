{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import trange\n",
    "from torch.nn import CrossEntropyLoss, L1Loss, MSELoss\n",
    "from torch.nn import functional as F\n",
    "import faiss\n",
    "import warnings\n",
    "import data_utils\n",
    "from eval_utils import cluster_metric\n",
    "import torch.distributions.normal as normal\n",
    "from model import Model, UD_constraint, CLIPModel\n",
    "import random\n",
    "import copy\n",
    "from loss_utils import DistillLoss, consistency_loss, entropy, ContrastiveInfoNCELoss, mutual_information\n",
    "from data_utils import NeighborsDataset, mine_nearest_neighbors\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def kmeans(X, cluster_num):\n",
    "    print(\"Running K-means clustering...\")\n",
    "    d = X.shape[1]  \n",
    "    kmeans = faiss.Kmeans(d, cluster_num, gpu=True, spherical=True, niter=300, nredo=20)\n",
    "    X = X.astype(np.float32)\n",
    "    kmeans.train(X)\n",
    "    D, I = kmeans.index.search(X, 1)\n",
    "    I = I.reshape(-1)\n",
    "    print(\"K-means clustering finished.\")\n",
    "    return I \n",
    "\n",
    "\n",
    "dataset = \"CIFAR-10\"  \n",
    "cluster_num = 10 \n",
    "dataloader_train, dataloader_test = data_utils.get_dataloader(\n",
    "    dataset=dataset, batch_size=1024\n",
    ")\n",
    "\n",
    "\n",
    "sample_image, _ = dataloader_train.dataset[0]\n",
    "feature_dim = sample_image.size()\n",
    "\n",
    "print(\"Feature dimension:\", feature_dim)\n",
    "\n",
    "model = CLIPModel(model_name=\"ViT-B/32\").cuda()\n",
    "model.eval()\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []   \n",
    "labels = []\n",
    "print(\"Inferencing features and labels for training set images...\") \n",
    "\n",
    "if os.path.exists(f\"/home/zixuanlin/data/data/{dataset}_image_embedding_train.npy\") and os.path.exists(f\"/home/zixuanlin/data/data/{dataset}_image_embedding_test.npy\"):\n",
    "    print(\"Found existing feature files, loading directly...\")\n",
    "    features = np.load(f\"/home/zixuanlin/data/data/{dataset}_image_embedding_train.npy\")\n",
    "    labels = np.loadtxt(f\"/home/zixuanlin/data/data/{dataset}_labels_train.txt\")\n",
    "    features_test = np.load(f\"/home/zixuanlin/data/data/{dataset}_image_embedding_test.npy\")\n",
    "    labels_test = np.loadtxt(f\"/home/zixuanlin/data/data/{dataset}_labels_test.txt\")\n",
    "    print(labels_test)\n",
    "    print(\"Training set features shape:\", features.shape, \"Training set labels shape:\", labels.shape)\n",
    "    print(\"Test set features shape:\", features_test.shape, \"Test set labels shape:\", labels_test.shape)\n",
    "    print(\"Loading completed.\")\n",
    "    train_num = features.shape[0]\n",
    "    print(\"Number of training samples:\", train_num) \n",
    "else:\n",
    "    for iteration, (x, y) in enumerate(dataloader_train):\n",
    "        x = x.cuda()\n",
    "        with torch.no_grad():\n",
    "            feature = model.encode_image(x)\n",
    "        features.append(feature.cpu().numpy())\n",
    "        labels.append(y.numpy())\n",
    "        if iteration % 10 == 0:\n",
    "            print(f\"[Iteration {iteration}/{len(dataloader_train)}]\")\n",
    "\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    print(\"Training set features shape:\", features.shape, \"Training set labels shape:\", labels.shape)\n",
    "    train_num = features.shape[0]\n",
    "    print(\"Number of training samples:\", train_num) \n",
    "    \n",
    "    features_test = []\n",
    "    labels_test = []\n",
    "    print(\"Inferencing features and labels for test set images...\")\n",
    "\n",
    "    for iteration, (x, y) in enumerate(dataloader_test):\n",
    "        x = x.cuda()\n",
    "        with torch.no_grad():\n",
    "            feature = model.encode_image(x)\n",
    "        features_test.append(feature.cpu().numpy())\n",
    "        labels_test.append(y.numpy())\n",
    "        if iteration % 10 == 0:\n",
    "            print(f\"[Iteration {iteration}/{len(dataloader_test)}]\")\n",
    "\n",
    "    features_test = np.concatenate(features_test, axis=0)\n",
    "    labels_test = np.concatenate(labels_test, axis=0)\n",
    "    print(\"Test set features shape:\", features_test.shape, \"Test set labels shape:\", labels_test.shape)\n",
    "    \n",
    "    if dataset == \"CIFAR-20\" or dataset == \"CIFAR-20-test\":\n",
    "        coarse_label = [\n",
    "            [72, 4, 95, 30, 55], [73, 32, 67, 91, 1], [92, 70, 82, 54, 62], [16, 61, 9, 10, 28],\n",
    "            [51, 0, 53, 57, 83], [40, 39, 22, 87, 86], [20, 25, 94, 84, 5], [14, 24, 6, 7, 18],\n",
    "            [43, 97, 42, 3, 88], [37, 17, 76, 12, 68], [49, 33, 71, 23, 60], [15, 21, 19, 31, 38],\n",
    "            [75, 63, 66, 64, 34], [77, 26, 45, 99, 79], [11, 2, 35, 46, 98], [29, 93, 27, 78, 44],\n",
    "            [65, 50, 74, 36, 80], [56, 52, 47, 59, 96], [8, 58, 90, 13, 48], [81, 69, 41, 89, 85]\n",
    "        ]\n",
    "        labels_copy = copy.deepcopy(labels)\n",
    "        labels_test_copy = copy.deepcopy(labels_test)\n",
    "        for i in range(20):\n",
    "            for j in coarse_label[i]:\n",
    "                labels[labels_copy == j] = i\n",
    "                labels_test[labels_test_copy == j] = i\n",
    "    \n",
    "    np.save(\"/home/zixuanlin/data/data/\" + dataset + \"_image_embedding_train.npy\", features)\n",
    "    np.save(\"/home/zixuanlin/data/data/\" + dataset + \"_image_embedding_test.npy\", features_test)\n",
    "    np.savetxt(\"/home/zixuanlin/data/data/\" + dataset + \"_labels_train.txt\", labels)\n",
    "    np.savetxt(\"/home/zixuanlin/data/data/\" + dataset + \"_labels_test.txt\", labels_test)\n",
    "    \n",
    "features_test = features_test / np.linalg.norm(features_test, axis=1, keepdims=True)\n",
    "cluster_labels = kmeans(features_test, cluster_num)\n",
    "cluster_metric(labels_test, cluster_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"/home/zixuanlin/data/data/{dataset}_retrieved_embedding.npy\"):\n",
    "    print(\"Found existing retrieved embedding file, loading...\")\n",
    "    retrieval_embedding = np.load(f\"/home/zixuanlin/data/data/{dataset}_retrieved_embedding.npy\")\n",
    "else: \n",
    "    cluster_num = 166\n",
    "    topK = 5\n",
    "\n",
    "    nouns_embedding = np.load(\"/home/zixuanlin/data/data/nouns_embedding_ensemble.npy\")\n",
    "    nouns_embedding = nouns_embedding / np.linalg.norm(nouns_embedding, axis=1, keepdims=True)\n",
    "    print(\"Noun embedding shape:\", nouns_embedding.shape)\n",
    "    \n",
    "    images_embedding = np.load(\"/home/zixuanlin/data/data/\" + dataset + \"_image_embedding_train.npy\")\n",
    "    images_embedding = images_embedding / np.linalg.norm(images_embedding, axis=1, keepdims=True)\n",
    "\n",
    "    nouns_embedding = torch.from_numpy(nouns_embedding).cuda().half()\n",
    "    nouns_num = nouns_embedding.shape[0]\n",
    "    images_embedding = torch.from_numpy(images_embedding).cuda().half()\n",
    "    image_num = images_embedding.shape[0]\n",
    "\n",
    "    try:\n",
    "        preds = np.load(\"/home/zixuanlin/data/data/\" + dataset + \"_image_\" + str(cluster_num) + \"cluster.npy\")\n",
    "    except:\n",
    "        preds = kmeans(images_embedding.cpu().numpy(), cluster_num)\n",
    "        np.save(\"/home/zixuanlin/data/data/\" + dataset + \"_image_\" + str(cluster_num) + \"cluster.npy\", preds)\n",
    "        print(\"Please rerun the script.\")\n",
    "        exit()\n",
    "\n",
    "    image_centers = torch.zeros((cluster_num, 512), dtype=torch.float16).cuda()\n",
    "    for k in range(cluster_num):\n",
    "        image_centers[k] = images_embedding[preds == k].mean(dim=0)\n",
    "    image_centers = F.normalize(image_centers, dim=1)\n",
    "\n",
    "    similarity = torch.matmul(image_centers, nouns_embedding.T)\n",
    "    softmax_nouns = torch.softmax(similarity, dim=0).cpu().float()\n",
    "    class_pred = torch.argmax(softmax_nouns, dim=0).long()\n",
    "\n",
    "    selected_idx = torch.zeros_like(class_pred, dtype=torch.bool)\n",
    "    for k in range(cluster_num):\n",
    "        if (class_pred == k).sum() == 0:\n",
    "            continue\n",
    "        class_index = torch.where(class_pred == k)[0]\n",
    "        softmax_class = softmax_nouns[:, class_index]\n",
    "        confidence = softmax_class.max(dim=0)[0]\n",
    "        rank = torch.argsort(confidence, descending=True)\n",
    "        selected_idx[class_index[rank[:topK]]] = True\n",
    "    selected_idx = selected_idx.cpu().numpy()\n",
    "\n",
    "    print(selected_idx.sum(), \"nouns selected.\")\n",
    "\n",
    "    nouns_embedding_selected = nouns_embedding[selected_idx]\n",
    "    np.save(\"/home/zixuanlin/data/data/\" + dataset + \"_filtered_nouns_embedding.npy\", nouns_embedding_selected.cpu().numpy())\n",
    "    \n",
    "    tau = 0.005\n",
    "\n",
    "    nouns_embedding = np.load(\"/home/zixuanlin/data/data/\" + dataset + \"_filtered_nouns_embedding.npy\")\n",
    "    nouns_embedding = nouns_embedding / np.linalg.norm(nouns_embedding, axis=1, keepdims=True)\n",
    "    images_embedding = np.load(\"/home/zixuanlin/data/data/\" + dataset + \"_image_embedding_train.npy\")\n",
    "    images_embedding = images_embedding / np.linalg.norm(images_embedding, axis=1, keepdims=True)\n",
    "\n",
    "    nouns_embedding = torch.from_numpy(nouns_embedding).cuda().half()\n",
    "    nouns_num = nouns_embedding.shape[0]\n",
    "    images_embedding = torch.from_numpy(images_embedding).cuda().half()\n",
    "    image_num = images_embedding.shape[0]\n",
    "\n",
    "    retrieval_embeddings = []\n",
    "    batch_size = 8192\n",
    "\n",
    "    for i in range(image_num // batch_size + 1):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        if end > image_num:\n",
    "            end = image_num\n",
    "        images_batch = images_embedding[start:end]\n",
    "        similarity = torch.matmul(images_embedding[start:end], nouns_embedding.T)\n",
    "        similarity = torch.softmax(similarity / tau, dim=1)\n",
    "        retrieval_embedding = (similarity @ nouns_embedding).cpu()\n",
    "        retrieval_embeddings.append(retrieval_embedding)\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[Completed {i * batch_size}/{image_num}]\")\n",
    "\n",
    "    retrieval_embedding = torch.cat(retrieval_embeddings, dim=0).cuda().half()\n",
    "    retrieval_embedding = F.normalize(retrieval_embedding, dim=1).cpu().numpy()\n",
    "    print(\"Retrieved embedding shape:\", retrieval_embedding.shape)\n",
    "    np.save(\"/home/zixuanlin/data/data/\" + dataset + \"_retrieved_nouns_embedding.npy\", retrieval_embedding)\n",
    "    \n",
    "    if dataset == \"CIFAR-10\" or dataset == \"STL-10\" or dataset == \"ImageNet-10\":\n",
    "        cluster_num = 10\n",
    "    elif dataset == \"CIFAR-20\":\n",
    "        cluster_num = 20\n",
    "    elif dataset == \"food-101\":\n",
    "        cluster_num = 101\n",
    "    elif dataset == \"Oxford-102\":\n",
    "        cluster_num = 102\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    tau = 0.005\n",
    "\n",
    "    images_embedding = np.load(\"/home/zixuanlin/data/data/\" + dataset + \"_image_embedding_test.npy\")\n",
    "    images_embedding = images_embedding / np.linalg.norm(images_embedding, axis=1, keepdims=True)\n",
    "    labels = np.loadtxt(\"/home/zixuanlin/data/data/\" + dataset + \"_labels_test.txt\")\n",
    "    nouns_embedding = np.load(\"/home/zixuanlin/data/data/\" + dataset + \"_filtered_nouns_embedding.npy\")\n",
    "    nouns_embedding = nouns_embedding / np.linalg.norm(nouns_embedding, axis=1, keepdims=True)\n",
    "\n",
    "    nouns_embedding = torch.from_numpy(nouns_embedding).cuda().half()\n",
    "    nouns_num = nouns_embedding.shape[0]\n",
    "    images_embedding = torch.from_numpy(images_embedding).cuda().half()\n",
    "    image_num = images_embedding.shape[0]\n",
    "\n",
    "    retrieval_embeddings = []\n",
    "    batch_size = 256\n",
    "\n",
    "    for i in range(image_num // batch_size + 1):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        if end > image_num:\n",
    "            end = image_num\n",
    "        images_batch = images_embedding[start:end]\n",
    "        similarity = torch.matmul(images_embedding[start:end], nouns_embedding.T)\n",
    "        similarity = torch.softmax(similarity / tau, dim=1)\n",
    "        retrieval_embedding = (similarity @ nouns_embedding).cpu()\n",
    "        retrieval_embeddings.append(retrieval_embedding)\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[Completed {i * batch_size}/{image_num}]\")\n",
    "\n",
    "    retrieval_embedding = torch.cat(retrieval_embeddings, dim=0).cuda().half()\n",
    "    retrieval_embedding = F.normalize(retrieval_embedding, dim=1).cpu().numpy()\n",
    "    images_embedding = images_embedding.cpu().numpy()\n",
    "    concat_embedding = np.concatenate([images_embedding, retrieval_embedding], axis=1)\n",
    "    np.save(\"/home/zixuanlin/data/data/\" + dataset + \"_retrieved_embedding.npy\", retrieval_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(2)\n",
    "             \n",
    "num_heads = 2\n",
    "output_dims = [cluster_num] * num_heads\n",
    "model = Model(num_heads=num_heads, output_dims=output_dims, in_channel=512).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=10, verbose=True)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "prior_loc = torch.zeros(512).to(device)\n",
    "prior_scale = torch.ones(512).to(device)\n",
    "prior = normal.Normal(prior_loc, prior_scale)\n",
    "\n",
    "max_ACC = 0\n",
    "\n",
    "features_test = torch.tensor(features_test, dtype=torch.float32).to(device)\n",
    "retrieval_embedding = torch.tensor(retrieval_embedding, dtype=torch.float32).to(device)\n",
    "print(\"features_test shape:\", features_test.shape)\n",
    "print(\"retrieval_embedding shape:\", retrieval_embedding.shape)\n",
    "\n",
    "for epoch in trange(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        outputs_img, encoder_img = model(features_test, forward_pass='output_i')\n",
    "        outputs_txt, encoder_txt = model(retrieval_embedding, forward_pass='output_i')\n",
    "\n",
    "        loss1 = sum(mutual_information(outputs_img[i], outputs_txt[i]) for i in range(num_heads))\n",
    "\n",
    "        z_img = model.encoder(features_test)\n",
    "        z_txt = model.encoder(retrieval_embedding)\n",
    "        z1 = z_img.rsample()\n",
    "        z2 = z_txt.rsample()\n",
    "        prior_sample = prior.sample()\n",
    "\n",
    "        z1 = F.log_softmax(z1, dim=-1)\n",
    "        z2 = F.log_softmax(z2, dim=-1)\n",
    "        prior_sample = F.softmax(prior_sample, dim=-1)\n",
    "\n",
    "        skl1 = torch.nn.functional.kl_div(z1, prior_sample, reduction='batchmean')\n",
    "        skl2 = torch.nn.functional.kl_div(z2, prior_sample, reduction='batchmean')\n",
    "        loss2 = skl1 + skl2\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            with torch.no_grad():\n",
    "                UDC = UD_constraint(model, features_test, num_heads)\n",
    "                UDC = UDC.to(device)\n",
    "        loss3 = criterion(outputs_img[-1], UDC) / 2\n",
    "\n",
    "        loss_g =  loss1 + loss2 + 5 * loss3\n",
    "\n",
    "    scaler.scale(loss_g).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    scheduler.step(loss_g)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs_eval, _ = model(features_test, forward_pass='output_i')\n",
    "            pre_label = outputs_eval[-1].argmax(dim=1).cpu().numpy()\n",
    "            acc,_,_ = cluster_metric(labels_test, pre_label)\n",
    "            print(f\"Epoch {epoch}, Loss: {loss_g.item()}\")\n",
    "        if acc > max_ACC:\n",
    "            max_ACC = acc\n",
    "            # torch.save(model.state_dict(), f\"model/Multi-head/{dataset}/model_{dataset}_{num_heads}_best.pth\")\n",
    "            print(f\"Save model to model/Multi-head/{dataset}/model_{dataset}_{num_heads}_best.pth\")\n",
    "print(f\"Best accuracy: {max_ACC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, dataloader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    logits_image = []\n",
    "    with torch.no_grad():\n",
    "        for iter, (image) in enumerate(dataloader):\n",
    "            image = image[0].cuda()\n",
    "            outputs, _ = model(image)\n",
    "            logit_image = outputs[-1]\n",
    "            pred = torch.argmax(logit_image, dim=1).cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            logits_image.append(logit_image.cpu().numpy())\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    logits_image = np.concatenate(logits_image, axis=0)\n",
    "    return preds, logits_image\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    epochs = 500\n",
    "    batch_size = 8192\n",
    "    temperature = 0.5     \n",
    "    topK = 5\n",
    "\n",
    "    nouns_embedding = np.load(\"/home/zixuanlin/data/data/\" + dataset + \"_retrieved_nouns_embedding.npy\")\n",
    "    nouns_embedding = nouns_embedding / np.linalg.norm(nouns_embedding, axis=1, keepdims=True)\n",
    "    images_embedding_train = np.load(\"/home/zixuanlin/data/data/\" + dataset + \"_image_embedding_train.npy\")\n",
    "    images_embedding_train = images_embedding_train / np.linalg.norm(images_embedding_train, axis=1, keepdims=True)\n",
    "    images_embedding_test = np.load(\"/home/zixuanlin/data/data/\" + dataset + \"_image_embedding_test.npy\")\n",
    "    images_embedding_test = images_embedding_test / np.linalg.norm(images_embedding_test, axis=1, keepdims=True)\n",
    "    labels_test = np.loadtxt(\"/home/zixuanlin/data/data/\" + dataset + \"_labels_test.txt\")\n",
    "\n",
    "    model.load_state_dict(torch.load(f\"model/Multi-head/{dataset}/model_{dataset}_{num_heads}_best.pth\"))\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.cluster_heads.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    dataset_text_train = TensorDataset(torch.from_numpy(nouns_embedding).float())\n",
    "    dataset_image_train = TensorDataset(torch.from_numpy(images_embedding_train).float())\n",
    "    dataset_image_test = TensorDataset(torch.from_numpy(images_embedding_test).float())\n",
    "\n",
    "    try:\n",
    "        indices_text = np.load(\"/home/zixuanlin/data/data/\" + dataset + \"_indices\" + str(topK) + \"_text.npy\")\n",
    "        indices_image = np.load(\"/home/zixuanlin/data/data/\" + dataset + \"_indices\" + str(topK) + \"_image.npy\")\n",
    "        print(\"Pre-computed indices loaded.\")\n",
    "    except:\n",
    "        indices_text = mine_nearest_neighbors(nouns_embedding, topk=topK)\n",
    "        indices_image = mine_nearest_neighbors(images_embedding_train, topk=topK)\n",
    "        np.save(\"/home/zixuanlin/data/data/\" + dataset + \"_indices\" + str(topK) + \"_text.npy\", indices_text)\n",
    "        np.save(\"/home/zixuanlin/data/data/\" + dataset + \"_indices\" + str(topK) + \"_image.npy\", indices_image)\n",
    "        print(\"Please rerun the script.\")\n",
    "        exit()\n",
    "\n",
    "    data_set = NeighborsDataset(dataset_text_train, dataset_image_train, indices_text, indices_image)\n",
    "    dataloader_train = DataLoader(data_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    dataloader_test = DataLoader(dataset_image_test, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.999))\n",
    "    distill_loss = DistillLoss(class_num=cluster_num, temperature=temperature)\n",
    "    contrastive_loss = ContrastiveInfoNCELoss(temperature=temperature)\n",
    "\n",
    "    def neighborhood_consistency_loss(logit_a, logit_b):\n",
    "        diff = logit_a - logit_b\n",
    "        loss = torch.mean(diff ** 2)\n",
    "        return loss\n",
    "\n",
    "    Macc = 0\n",
    "    print(\"Start training...\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss_distill_epoch = loss_consist_epoch = loss_entropy_epoch = loss_contrastive_epoch = 0\n",
    "        for iter, (text, image, neigh_text, neigh_image) in enumerate(dataloader_train):\n",
    "            image = image[0].cuda()\n",
    "            neigh_image = neigh_image[0].cuda()\n",
    "\n",
    "            outputs, _ = model(image)\n",
    "            neigh_outputs, _ = model(neigh_image)\n",
    "\n",
    "            logit_image_all = [output for output in outputs]\n",
    "            logit_neigh_all = [output for output in neigh_outputs]\n",
    "\n",
    "            loss_distill_all = 0\n",
    "            for i in range(num_heads - 1):\n",
    "                loss_distill_all += distill_loss(logit_image_all[i], logit_neigh_all[i])\n",
    "\n",
    "            loss_consist_all = 0\n",
    "            loss_entropy_all = 0\n",
    "            for logit_image, logit_neigh in zip(logit_image_all, logit_neigh_all):\n",
    "                loss_consist_all += consistency_loss(logit_image, logit_neigh)\n",
    "                loss_entropy_all += entropy(logit_image)\n",
    "\n",
    "            loss = loss_distill_all  + 1 * loss_consist_all - 10 * loss_entropy_all\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_distill_epoch += loss_distill_all.item()\n",
    "            loss_entropy_epoch += loss_entropy_all.item()\n",
    "\n",
    "            if (iter + 1) % 50 == 0 or iter + 1 == len(dataloader_train):\n",
    "                print(\n",
    "                    f\"[Epoch {epoch+1}/{epochs}] [Iter {iter+1}/{len(dataloader_train)}] \"\n",
    "                    f\"Loss Distill: {loss_distill_all.item():.4f} Loss Entropy: {loss_entropy_all.item():.4f}\"\n",
    "                )\n",
    "\n",
    "        preds, confidences_image = infer(model, dataloader_test)\n",
    "        acc, nmi, ari = cluster_metric(labels_test, preds)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - ACC: {acc:.4f}, NMI: {nmi:.4f}, ARI: {ari:.4f}\")\n",
    "        if acc > Macc:\n",
    "            Macc = acc\n",
    "\n",
    "    print(f\"Final Max Acc: {Macc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TAC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
